{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import mxnet as mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_GPUS = 8\n",
    "mb_size = 60#*N_GPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to4d(img):\n",
    "    \"\"\"\n",
    "    reshape to 4D arrays\n",
    "    \"\"\"\n",
    "    return img.reshape(img.shape[0], 1, 28, 28).astype(np.float32)/255\n",
    "\n",
    "def get_mnist_iter():\n",
    "    \"\"\"\n",
    "    create data iterator with NDArrayIter\n",
    "    \"\"\"\n",
    "    (train_lbl, train_img) = (mnist.train.labels, mnist.train.images)\n",
    "    (val_lbl, val_img) = (mnist.test.labels, mnist.test.images)\n",
    "    train_img = (train_img-0.5)*2\n",
    "    val_img = (val_img-0.5)*2\n",
    "    \n",
    "    train = mx.io.NDArrayIter(\n",
    "        to4d(train_img), train_lbl, mb_size, shuffle=True)\n",
    "    val = mx.io.NDArrayIter(\n",
    "        to4d(val_img), val_lbl, mb_size)\n",
    "    return (train, val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RandIter(mx.io.DataIter):\n",
    "    def __init__(self, batch_size, ndim):\n",
    "        self.batch_size = batch_size\n",
    "        self.ndim = ndim\n",
    "        self.provide_data = [('z', (batch_size, ndim))]\n",
    "        self.provide_label = []\n",
    "\n",
    "    def iter_next(self):\n",
    "        return True\n",
    "\n",
    "    def getdata(self):\n",
    "        #Returns random numbers from a gaussian (normal) distribution \n",
    "        #with mean=0 and standard deviation = 1\n",
    "        return [mx.random.normal(0, 1.0, shape=(self.batch_size, self.ndim))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_simple():\n",
    "    data = mx.sym.Variable('data')\n",
    "    fc1 = mx.sym.FullyConnected(data, name='fc1', num_hidden=128)\n",
    "    act1 = mx.sym.Activation(fc1, name='relu1', act_type=\"relu\")\n",
    "    fc2 = mx.sym.FullyConnected(act1, name='fc2', num_hidden=10)\n",
    "    fc_do = mx.sym.Dropout(fc2, p=0.5)\n",
    "    out = mx.sym.SoftmaxOutput(fc_do, name = 'softmax')\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv():\n",
    "    data = mx.sym.Variable('data')\n",
    "    conv1 = mx.sym.Convolution(\n",
    "        data,\n",
    "        name='conv1',\n",
    "        kernel=(5,5),\n",
    "        stride=(1,1),\n",
    "        num_filter=128,\n",
    "    )\n",
    "    act1 = mx.sym.LeakyReLU(conv1, name='lrelu1')\n",
    "    \n",
    "    conv2 = mx.sym.Convolution(\n",
    "        mx.sym.BatchNorm(act1),\n",
    "        name='conv2',\n",
    "        kernel=(5,5),\n",
    "        stride=(2,2),\n",
    "        num_filter=256,\n",
    "    )\n",
    "    act2 = mx.sym.LeakyReLU(conv2, name='lrelu2')\n",
    "    \n",
    "    conv3 = mx.sym.Convolution(\n",
    "        mx.sym.BatchNorm(act2),\n",
    "        name='conv3',\n",
    "        kernel=(5,5),\n",
    "        stride=(2,2),\n",
    "        num_filter=512,\n",
    "    )\n",
    "    act3 = mx.sym.LeakyReLU(conv3, name='lrelu3')\n",
    "    \n",
    "    fc = mx.sym.FullyConnected(act3, name='fc', num_hidden=10)\n",
    "    \n",
    "    fc_do = mx.sym.Dropout(fc, p=0.5)\n",
    "    \n",
    "    out = mx.sym.SoftmaxOutput(fc_do, name = 'softmax')\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_discriminator():\n",
    "    data = mx.sym.Variable('data')\n",
    "    conv1 = mx.sym.Convolution(\n",
    "        data,\n",
    "        name='conv1',\n",
    "        kernel=(5,5),\n",
    "        stride=(1,1),\n",
    "        num_filter=128,\n",
    "    )\n",
    "    conv1_bn = mx.sym.BatchNorm(conv1, name='conv1_bn')\n",
    "    act1 = mx.sym.LeakyReLU(conv1_bn, name='lrelu1')\n",
    "    \n",
    "    conv2 = mx.sym.Convolution(\n",
    "        act1,\n",
    "        name='conv2',\n",
    "        kernel=(5,5),\n",
    "        stride=(2,2),\n",
    "        pad=(2,2),\n",
    "        num_filter=256,\n",
    "    )\n",
    "    conv2_bn = mx.sym.BatchNorm(conv2, name='conv2_bn')\n",
    "    act2 = mx.sym.LeakyReLU(conv2_bn, name='lrelu2')\n",
    "    \n",
    "    conv3 = mx.sym.Convolution(\n",
    "        act2,\n",
    "        name='conv3',\n",
    "        kernel=(5,5),\n",
    "        stride=(2,2),\n",
    "        pad=(2,2),\n",
    "        num_filter=512,\n",
    "    )\n",
    "    conv3_bn = mx.sym.BatchNorm(conv3, name='conv3_bn')\n",
    "    act3 = mx.sym.LeakyReLU(conv3_bn, name='lrelu3')\n",
    "    \n",
    "    conv4 = mx.sym.Convolution(\n",
    "        act3,\n",
    "        name='conv4',\n",
    "        kernel=(5,5),\n",
    "        num_filter=1,\n",
    "    )\n",
    "    flat_bn = mx.sym.flatten(mx.sym.BatchNorm(conv4), name='conv4_flat_bn')\n",
    "    \n",
    "    fc = mx.sym.FullyConnected(flat_bn, num_hidden=1, name='fc_output')\n",
    "    label = mx.sym.Variable('label')\n",
    "    out = mx.sym.LogisticRegressionOutput(data=fc, label=label, name='LogRegOut')\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_generator():\n",
    "    z = mx.sym.Variable('z')\n",
    "    g_fc = mx.sym.FullyConnected(\n",
    "        z,\n",
    "        num_hidden=7*7*512,\n",
    "    )\n",
    "    g_fc_reshape = mx.symbol.reshape(\n",
    "        g_fc,\n",
    "        shape=(-1,512,7,7)\n",
    "    )\n",
    "    gbn1 = mx.sym.BatchNorm(g_fc_reshape, name='gbn1')\n",
    "    gact1 = mx.sym.Activation(gbn1, name='gact1', act_type='relu')\n",
    "    \n",
    "    g2 = mx.sym.Deconvolution(\n",
    "        gact1, \n",
    "        name='g2', \n",
    "        kernel=(5,5), \n",
    "        stride=(2,2), \n",
    "        target_shape=(14,14),\n",
    "        num_filter=256,\n",
    "    )\n",
    "    gbn2 = mx.sym.BatchNorm(g2, name='gbn2')\n",
    "    gact2 = mx.sym.Activation(gbn2, name='gact2', act_type='relu')\n",
    "\n",
    "    g3 = mx.sym.Deconvolution(\n",
    "        gact2, \n",
    "        name='g3', \n",
    "        kernel=(5,5), \n",
    "        stride=(2,2), \n",
    "        target_shape=(28,28),\n",
    "        num_filter=128\n",
    "    )\n",
    "    gbn3 = mx.sym.BatchNorm(g3, name='gbn3')\n",
    "    gact3 = mx.sym.Activation(gbn3, name='gact3', act_type='relu')\n",
    "\n",
    "    g4 = mx.sym.Deconvolution(\n",
    "        gact3, \n",
    "        name='g4', \n",
    "        kernel=(5,5), \n",
    "        stride=(1,1), \n",
    "        target_shape=(28,28), \n",
    "        num_filter=1\n",
    "    )\n",
    "    gbn4 = mx.sym.BatchNorm(g4, name='gbn4')\n",
    "    gact4 = mx.sym.Activation(gbn4, name='gan_output', act_type='tanh')\n",
    "    \n",
    "    return gact4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discriminatorSymbol = get_discriminator()\n",
    "generatorSymbol = get_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mx.viz.plot_network(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1000, 1)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg, d_out_shape, aux = discriminatorSymbol.infer_shape(data=(1000,1,28,28), label=(1000,1))\n",
    "d_out_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(64, 1, 28, 28)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg, g_out_shape, aux = generatorSymbol.infer_shape(z=(64,100))\n",
    "g_out_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_dim = 100\n",
    "noise_iter = RandIter(mb_size, z_dim)\n",
    "train, val = get_mnist_iter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ctx = [mx.gpu(i) for i in range(N_GPUS)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lr = 0.0002\n",
    "lr = 0.0005\n",
    "beta1 = 0.5\n",
    "\n",
    "generator = mx.module.Module(generatorSymbol, data_names=('z',), label_names=None, context=ctx)\n",
    "generator.bind(data_shapes=noise_iter.provide_data)\n",
    "generator.init_params(initializer=mx.init.Xavier())\n",
    "generator.init_optimizer(\n",
    "    optimizer='adam',\n",
    "    optimizer_params={\n",
    "        'learning_rate': lr,\n",
    "        'beta1': beta1,\n",
    "    })\n",
    "mods = [generator]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "discriminator = mx.module.Module(discriminatorSymbol, data_names=('data',), label_names=('label',), context=ctx)\n",
    "discriminator.bind(\n",
    "    data_shapes=train.provide_data,\n",
    "    label_shapes=[('label', (mb_size,))],\n",
    "    inputs_need_grad=True\n",
    ")\n",
    "discriminator.init_params(initializer=mx.init.Xavier())\n",
    "discriminator.init_optimizer(\n",
    "    optimizer='adam',\n",
    "    optimizer_params={\n",
    "        'learning_rate': lr,\n",
    "        'beta1': beta1,\n",
    "    })\n",
    "mods.append(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot(samples):\n",
    "    fig = plt.figure(figsize=(4, 4))\n",
    "    gs = gridspec.GridSpec(4, 4)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    "\n",
    "    #return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "epoch: 0 iter: 0\n",
      "epoch: 1 iter: 0\n",
      "epoch: 2 iter: 0\n",
      "epoch: 3 iter: 0\n",
      "epoch: 4 iter: 0\n",
      "epoch: 5 iter: 0\n",
      "epoch: 6 iter: 0\n",
      "epoch: 7 iter: 0\n",
      "epoch: 8 iter: 0\n",
      "epoch: 9 iter: 0\n"
     ]
    }
   ],
   "source": [
    "print('Training...')\n",
    "for epoch in range(10):\n",
    "    train.reset()\n",
    "    for i, batch in enumerate(train):\n",
    "        #Get a batch of random numbers to generate an image from the generator\n",
    "        zbatch = noise_iter.next()\n",
    "        #Forward pass on training batch\n",
    "        generator.forward(zbatch, is_train=True)\n",
    "        #Output of training batch is the 64x64x3 image\n",
    "        outG = generator.get_outputs()\n",
    "        \n",
    "        #Pass the generated (fake) image through the discriminator, and save the gradient\n",
    "        #Label (for logistic regression) is an array of 0's since this image is fake\n",
    "        label = mx.nd.zeros((mb_size,), ctx=mx.gpu(0))\n",
    "        #Forward pass on the output of the discriminator network\n",
    "        discriminator.forward(mx.io.DataBatch(outG, [label]), is_train=True)\n",
    "        #Do the backwards pass and save the gradient\n",
    "        discriminator.backward()\n",
    "        gradD = [[grad.copyto(grad.context) for grad in grads] for grads in discriminator._exec_group.grad_arrays]\n",
    "        \n",
    "        #Pass a batch of real images from MNIST through the discriminator\n",
    "        #Set the label to be an array of 1's because these are the real images\n",
    "        label[:] = 1\n",
    "        batch.label = [label]\n",
    "        #Forward pass on a batch of MNIST images\n",
    "        discriminator.forward(batch, is_train=True)\n",
    "        #Do the backwards pass and add the saved gradient from the fake images to the gradient \n",
    "        #generated by this backwards pass on the real images\n",
    "        discriminator.backward()\n",
    "        for gradsr, gradsf in zip(discriminator._exec_group.grad_arrays, gradD):\n",
    "            for gradr, gradf in zip(gradsr, gradsf):\n",
    "                gradr += gradf\n",
    "        #Update gradient on the discriminator \n",
    "        discriminator.update()\n",
    "\n",
    "        #Now that we've updated the discriminator, let's update the generator\n",
    "        #First do a forward pass and backwards pass on the newly updated discriminator\n",
    "        #With the current batch\n",
    "        discriminator.forward(mx.io.DataBatch(outG, [label]), is_train=True)\n",
    "        discriminator.backward()\n",
    "        #Get the input gradient from the backwards pass on the discriminator,\n",
    "        #and use it to do the backwards pass on the generator\n",
    "        diffD = discriminator.get_input_grads()\n",
    "        generator.backward(diffD)\n",
    "        #Update the gradients on the generator\n",
    "        generator.update()\n",
    "        \n",
    "        #Increment to the next batch, printing every 50 batches\n",
    "        #i += 1\n",
    "        if i % 1000 == 0:\n",
    "            print('epoch:', epoch, 'iter:', i)\n",
    "            #plot(outG[0][:16].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot(outG[0][:16].asnumpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#score = mod.score(val, ['acc'])\n",
    "#print(\"Accuracy score is %f\" % (score[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
